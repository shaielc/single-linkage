{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_cube.dat import read_dat_file, Header\n",
    "import numpy as np\n",
    "header = Header.read_header(\"self_test_rad.hdr\")\n",
    "img = read_dat_file(\"self_test_rad.img\", header).astype(np.float32)\n",
    "cache_path = \"D:\\\\SingleLinkage\\\\diff.cache\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Tree:\n",
    "    count = 0\n",
    "\n",
    "    def __init__(self, members: list):\n",
    "        self.members = members\n",
    "        self._contains = set.union(*map(lambda tree: tree._contains, members)) if len(members) > 0 else set()\n",
    "        self.index = Tree.count\n",
    "        Tree.count+=1\n",
    "    \n",
    "    def join(self, other):\n",
    "        return Tree([self, other])\n",
    "    \n",
    "    def clear(self,):\n",
    "#         print(self.index)\n",
    "        self._contains = None\n",
    "\n",
    "    def num_of_members(self,):\n",
    "        return len(self.members)\n",
    "    \n",
    "    def __iter__(self,):\n",
    "        yield from self._contains\n",
    "    \n",
    "    def __contains__(self, i):\n",
    "        return i in self._contains\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(tuple(leaf for leaf in self))\n",
    "\n",
    "class Leaf(Tree):\n",
    "    def __init__(self, value) -> None:\n",
    "        self.value = value\n",
    "        super().__init__([])\n",
    "        self._contains = {value}\n",
    "\n",
    "\n",
    "def triangle_offset(i, n):\n",
    "    return (2*i*n-i**2-i)//2\n",
    "\n",
    "# Iterate through a strictly upper-triangular matrix line by line.\n",
    "def iterate_triangle(cache_path, height, batch_size=100):\n",
    "    batch_size = min(batch_size,height)\n",
    "    partition = np.fromfile(cache_path, dtype=np.float16, offset=0, count=triangle_offset(batch_size,height))\n",
    "    partition_offset = 0\n",
    "    for i in tqdm(range(height-1)):\n",
    "        start = triangle_offset(i, height)\n",
    "        end = triangle_offset(i+1, height)\n",
    "        if (i+1) % batch_size == 0:\n",
    "            partition =  np.fromfile(cache_path, dtype=np.float16, offset=start*2, count=triangle_offset(i+batch_size,height) - start)\n",
    "            partition_offset = start\n",
    "        yield i, partition[start - partition_offset:end - partition_offset]\n",
    "\n",
    "def get_kth_min(cache_path, vector_index, k, height):\n",
    "    start = triangle_offset(vector_index, height)\n",
    "    end = triangle_offset(vector_index+1, height)\n",
    "    vector = np.fromfile(cache_path, dtype=np.float16, count=(end-start), offset=start*2)\n",
    "    kth_argmin = np.argpartition(vector, k)[k]\n",
    "    kth_min = vector[kth_argmin]\n",
    "    return kth_argmin, kth_min\n",
    "\n",
    "fimg = img.reshape(-1, img.shape[2])\n",
    "\n",
    "trees = {}\n",
    "for i in range(fimg.shape[0]):\n",
    "    leaf = Leaf(i)\n",
    "    trees[leaf.index] = leaf\n",
    "\n",
    "_current_min = np.zeros(fimg.shape[0],)\n",
    "_current_min_pairs = np.zeros(fimg.shape[0], dtype=int)\n",
    "\n",
    "for i, vector in iterate_triangle(cache_path, fimg.shape[0], batch_size=10000):\n",
    "    _current_min_pairs[i] = np.argmin(vector).astype(int)\n",
    "    _current_min[i] = vector[_current_min_pairs[i]]\n",
    "\n",
    "_current_min_pairs.astype(np.int32).tofile(\"initial_current_min_pairs.cache\")\n",
    "_current_min.astype(np.float64).tofile(\"initial_current_min.cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from process_cube.dat import read_dat_file, Header\n",
    "from functools import lru_cache\n",
    "\n",
    "header = Header.read_header(\"self_test_rad.hdr\")\n",
    "img = read_dat_file(\"self_test_rad.img\", header).astype(np.float32)\n",
    "fimg = img.reshape(-1, img.shape[2])\n",
    "cache_path = \"D:\\\\SingleLinkage\\\\diff.cache\"\n",
    "\n",
    "class Tree:\n",
    "    count = 0\n",
    "\n",
    "    def __init__(self, members: list):\n",
    "        self.members = members\n",
    "        self._contains = set.union(*map(lambda tree: tree._contains, members)) if len(members) > 0 else set()\n",
    "        self.index = Tree.count\n",
    "        Tree.count+=1\n",
    "    \n",
    "    def join(self, other):\n",
    "        return Tree([self, other])\n",
    "    \n",
    "    def clear(self,):\n",
    "#         print(self.index)\n",
    "        self._contains = None\n",
    "\n",
    "    def num_of_members(self,):\n",
    "        return len(self.members)\n",
    "    \n",
    "    def __iter__(self,):\n",
    "        yield from self._contains\n",
    "    \n",
    "    def __contains__(self, i):\n",
    "        return i in self._contains\n",
    "        \n",
    "    def __len__(self,):\n",
    "        return len(tuple(leaf for leaf in self))\n",
    "\n",
    "class Leaf(Tree):\n",
    "    def __init__(self, value) -> None:\n",
    "        self.value = value\n",
    "        super().__init__([])\n",
    "        self._contains = {value}\n",
    "\n",
    "def get_vector(cache_path, vector_index, height):\n",
    "    start = triangle_offset(vector_index, height)\n",
    "    end = triangle_offset(vector_index+1, height)\n",
    "    count = end - start\n",
    "    return np.fromfile(cache_path, dtype=np.float16, count=count, offset=start*2)\n",
    "    return np.linalg.norm(fimg[vector_index]-fimg[vector_index+1:],axis=-1)\n",
    "\n",
    "@lru_cache(20000)\n",
    "def get_argsort(cache_path, vector_index, height):\n",
    "    vector = get_vector(cache_path, vector_index, height)\n",
    "    \n",
    "    # argpartition is faster the difference is negligible for k > 1000, which is common - caching should outperform.\n",
    "    return np.argsort(vector), vector\n",
    "\n",
    "def get_kth_min(cache_path, vector_index, k, height):\n",
    "    argsort, vector = get_argsort(cache_path, vector_index, height)\n",
    "    if k >= len(vector):\n",
    "        return k, np.inf\n",
    "    \n",
    "    kth_argmin = argsort[k] \n",
    "    kth_min = vector[kth_argmin]\n",
    "    return kth_argmin, kth_min\n",
    "\n",
    "def triangle_offset(i, n):\n",
    "    return (2*i*n-i**2-i)//2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005028724670410156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 12,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 224000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad56cba1c4b47acbca777acc9a2e4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/224000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "current_min_pairs = np.fromfile(\"initial_current_min_pairs.cache\", dtype=np.int32)[:fimg.shape[0] - 1]\n",
    "current_min = np.fromfile(\"initial_current_min.cache\", dtype=np.float64)[:fimg.shape[0] - 1]\n",
    "current_k = np.zeros(fimg.shape[0], dtype=int)\n",
    "\n",
    "Tree.count = 0\n",
    "Leaf.count = 0\n",
    "trees = {}\n",
    "for i in range(fimg.shape[0]):\n",
    "    leaf = Leaf(i)\n",
    "    trees[leaf.index] = leaf\n",
    "\n",
    "out_trees = set()\n",
    "    \n",
    "max_len = 0\n",
    "\n",
    "edges_count = 0\n",
    "pb = tqdm(total=fimg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "text/plain": [
       "         2245025924 function calls in 18081.568 seconds\n",
       "\n",
       "   Ordered by: internal time\n",
       "\n",
       "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
       "   674836 5827.382    0.009 5827.382    0.009 {method 'argsort' of 'numpy.ndarray' objects}\n",
       "   674837 5548.974    0.008 5551.239    0.008 {built-in method numpy.fromfile}\n",
       "        1 3281.885 3281.885 18081.566 18081.566 <string>:1(<module>)\n",
       "  1566664 1553.007    0.001 1553.007    0.001 <string>:1(get_root_tree)\n",
       "730457591  849.731    0.000 12313.941    0.000 1520836299.py:59(get_kth_min)\n",
       "732942918  379.563    0.000  379.563    0.000 1520836299.py:33(__contains__)\n",
       "   216000  232.110    0.001  232.110    0.001 {method 'union' of 'set' objects}\n",
       "   432000  133.316    0.000  133.316    0.000 1520836299.py:23(clear)\n",
       "   783332  127.750    0.000  127.750    0.000 {method 'argmin' of 'numpy.ndarray' objects}\n",
       "731943366   65.607    0.000   65.607    0.000 {built-in method builtins.len}\n",
       "   141086    9.210    0.000    9.210    0.000 socket.py:545(send)\n",
       "   674837    4.429    0.000 11398.872    0.017 1520836299.py:52(get_argsort)\n",
       "   564344    4.403    0.000    6.779    0.000 encoder.py:204(iterencode)\n",
       "   674837    3.689    0.000 5557.785    0.008 1520836299.py:45(get_vector)\n",
       "  1349674    2.858    0.000    2.858    0.000 1520836299.py:68(triangle_offset)\n",
       "   216000    2.423    0.000  234.678    0.001 1520836299.py:14(__init__)\n",
       "   674836    2.388    0.000 5832.427    0.009 fromnumeric.py:1012(argsort)\n",
       "   674836    2.144    0.000 5830.039    0.009 fromnumeric.py:51(_wrapfunc)\n",
       "   674836    1.993    0.000 5834.420    0.009 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
       "  4796636    1.963    0.000    3.302    0.000 traitlets.py:692(__get__)\n",
       "    70495    1.846    0.000    3.473    0.000 std.py:355(format_meter)\n",
       "   674836    1.827    0.000 5836.659    0.009 <__array_function__ internals>:177(argsort)\n",
       "   141086    1.824    0.000   32.589    0.000 session.py:751(send)\n",
       "   674837    1.678    0.000    1.678    0.000 {built-in method _abc._abc_instancecheck}\n",
       "   282172    1.521    0.000    1.574    0.000 {method 'isoformat' of 'datetime.datetime' objects}\n",
       "   216000    1.496    0.000   55.818    0.000 std.py:1197(update)\n",
       "  4514464    1.339    0.000    1.339    0.000 traitlets.py:654(get)\n",
       "   141086    1.254    0.000   34.775    0.000 comm.py:21(publish_msg)\n",
       "    70495    1.235    0.000   52.324    0.001 notebook.py:149(display)\n",
       "   564344    1.080    0.000    9.422    0.000 __init__.py:183(dumps)\n",
       "   141086    1.032    0.000   41.921    0.000 widget.py:691(notify_change)\n",
       "   216000    1.026    0.000   56.844    0.000 notebook.py:267(update)\n",
       "   141086    1.013    0.000   15.264    0.000 session.py:687(serialize)\n",
       "   493465    0.942    0.000    0.942    0.000 {method 'format' of 'str' objects}\n",
       "  1269392    0.938    0.000    0.938    0.000 {built-in method builtins.hasattr}\n",
       "   564344    0.894    0.000    7.911    0.000 encoder.py:182(encode)\n",
       "  1380266    0.834    0.000    1.013    0.000 {built-in method builtins.getattr}\n",
       "   422970    0.814    0.000    0.814    0.000 std.py:233(__call__)\n",
       "   564344    0.776    0.000   10.424    0.000 session.py:97(json_packer)\n",
       "  3315379    0.689    0.000    0.689    0.000 {built-in method builtins.isinstance}\n",
       "   141086    0.665    0.000   38.524    0.000 widget.py:570(send_state)\n",
       "   141086    0.632    0.000    3.319    0.000 session.py:672(sign)\n",
       "   141086    0.629    0.000   10.659    0.000 iostream.py:202(schedule)\n",
       "   423258    0.601    0.000    0.601    0.000 {method 'copy' of '_hashlib.HASH' objects}\n",
       "   674837    0.587    0.000    2.264    0.000 abc.py:96(__instancecheck__)\n",
       "   216000    0.581    0.000  235.259    0.001 1520836299.py:20(join)\n",
       "    70495    0.574    0.000    1.643    0.000 std.py:1445(format_dict)\n",
       "   705430    0.546    0.000    0.546    0.000 {method 'update' of '_hashlib.HASH' objects}\n",
       "   211485    0.495    0.000   44.685    0.000 traitlets.py:705(set)\n",
       "    70495    0.494    0.000    0.902    0.000 notebook.py:200(colour)\n",
       "   141086    0.493    0.000    3.131    0.000 session.py:646(msg)\n",
       "   282172    0.491    0.000    0.935    0.000 traitlets.py:1916(trait_metadata)\n",
       "   141086    0.490    0.000    0.733    0.000 session.py:599(msg_id)\n",
       "   141087    0.468    0.000    0.707    0.000 traitlets.py:1518(_notify_observers)\n",
       "   282172    0.465    0.000    2.376    0.000 jsonutil.py:108(json_default)\n",
       "   141086    0.458    0.000   42.379    0.000 traitlets.py:1503(_notify_trait)\n",
       "   141086    0.451    0.000    1.328    0.000 widget.py:589(get_state)\n",
       "   564344    0.431    0.000    0.431    0.000 encoder.py:104(__init__)\n",
       "   211486    0.424    0.000    1.811    0.000 traitlets.py:734(_validate)\n",
       "   211485    0.420    0.000    0.995    0.000 traitlets.py:743(_cross_validate)\n",
       "   141086    0.413    0.000   35.765    0.000 widget.py:822(_send)\n",
       "   674836    0.412    0.000    0.412    0.000 fromnumeric.py:1008(_argsort_dispatcher)\n",
       "   141086    0.408    0.000    0.408    0.000 {method 'replace' of 'datetime.datetime' objects}\n",
       "   141086    0.388    0.000    2.337    0.000 session.py:643(msg_header)\n",
       "    70495    0.384    0.000   53.509    0.001 std.py:1324(refresh)\n",
       "   141086    0.382    0.000    0.982    0.000 hmac.py:115(copy)\n",
       "   141086    0.368    0.000    0.536    0.000 widget.py:85(_separate_buffers)\n",
       "   141086    0.329    0.000    1.035    0.000 widget.py:739(_should_send_property)\n",
       "   141086    0.319    0.000    0.614    0.000 threading.py:1089(is_alive)\n",
       "  1128112    0.319    0.000    0.319    0.000 {method 'replace' of 'str' objects}\n",
       "   141086    0.310    0.000   11.145    0.000 iostream.py:283(send_multipart)\n",
       "   141086    0.281    0.000   35.056    0.000 base_comm.py:111(send)\n",
       "    70495    0.271    0.000    0.271    0.000 {method 'split' of 're.Pattern' objects}\n",
       "   705430    0.266    0.000    0.266    0.000 {method 'encode' of 'str' objects}\n",
       "   141086    0.264    0.000    0.264    0.000 {method 'digest' of '_hashlib.HASH' objects}\n",
       "    70495    0.256    0.000    0.529    0.000 std.py:104(acquire)\n",
       "   140990    0.241    0.000    0.701    0.000 std.py:288(format_interval)\n",
       "   141086    0.232    0.000    0.757    0.000 session.py:201(utcnow)\n",
       "   141086    0.217    0.000    0.366    0.000 session.py:850(<listcomp>)\n",
       "   211485    0.217    0.000   44.902    0.000 traitlets.py:723(__set__)\n",
       "    70495    0.214    0.000    0.214    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
       "   564344    0.200    0.000    0.723    0.000 hmac.py:111(update)\n",
       "   141086    0.200    0.000    0.376    0.000 traitlets.py:1885(traits)\n",
       "    70495    0.198    0.000    0.198    0.000 {built-in method now}\n",
       "   140990    0.193    0.000    0.321    0.000 __init__.py:12(escape)\n",
       "   141086    0.176    0.000   10.835    0.000 iostream.py:214(send_multipart)\n",
       "   282172    0.174    0.000    0.174    0.000 {method 'copy' of 'dict' objects}\n",
       "    70495    0.172    0.000    0.272    0.000 std.py:108(release)\n",
       "   282172    0.170    0.000    0.170    0.000 jsonutil.py:39(_ensure_tzinfo)\n",
       "   141086    0.170    0.000    0.170    0.000 iostream.py:90(_event_pipe)\n",
       "   141086    0.158    0.000    0.158    0.000 {built-in method builtins.locals}\n",
       "   141086    0.158    0.000    0.503    0.000 hmac.py:128(_current)\n",
       "   141086    0.157    0.000    0.300    0.000 kernelbase.py:617(get_parent)\n",
       "    70495    0.155    0.000    0.439    0.000 traitlets.py:1229(__call__)\n",
       "   141086    0.155    0.000    0.155    0.000 {method 'hexdigest' of '_hashlib.HASH' objects}\n",
       "    70495    0.150    0.000    0.249    0.000 re.py:289(_compile)\n",
       "   141086    0.139    0.000    1.054    0.000 session.py:273(msg_header)\n",
       "   141086    0.139    0.000    0.675    0.000 widget.py:130(_remove_buffers)\n",
       "   282172    0.138    0.000    0.138    0.000 jsonutil.py:77(json_clean)\n",
       "    70495    0.130    0.000    0.650    0.000 re.py:223(split)\n",
       "   141086    0.126    0.000    0.126    0.000 {method 'acquire' of '_thread.lock' objects}\n",
       "   249983    0.126    0.000    0.126    0.000 {built-in method time.time}\n",
       "   564344    0.125    0.000    0.125    0.000 {method 'get' of 'dict' objects}\n",
       "    70495    0.124    0.000    0.244    0.000 widget_float.py:33(_validate_value)\n",
       "   141086    0.122    0.000    0.122    0.000 {built-in method builtins.max}\n",
       "   282172    0.122    0.000    0.122    0.000 {built-in method nt.getpid}\n",
       "   282076    0.119    0.000    0.119    0.000 {method 'update' of 'dict' objects}\n",
       "   141086    0.119    0.000    0.245    0.000 threading.py:1035(_wait_for_tstate_lock)\n",
       "   141086    0.117    0.000    0.227    0.000 configurable.py:565(initialized)\n",
       "   141086    0.117    0.000    0.775    0.000 hmac.py:147(hexdigest)\n",
       "   141086    0.117    0.000    0.117    0.000 {built-in method utcnow}\n",
       "    70495    0.115    0.000    0.196    0.000 traitlets.py:2435(validate)\n",
       "   141086    0.111    0.000    0.818    0.000 traitlets.py:1514(notify_change)\n",
       "   141086    0.105    0.000    0.121    0.000 session.py:280(extract_header)\n",
       "   281980    0.084    0.000    0.084    0.000 {built-in method builtins.divmod}\n",
       "    70495    0.081    0.000    0.081    0.000 traitlets.py:2339(_validate_bounds)\n",
       "   564344    0.078    0.000    0.078    0.000 {method 'join' of 'str' objects}\n",
       "   432000    0.072    0.000    0.072    0.000 1520836299.py:16(<lambda>)\n",
       "    70495    0.071    0.000    0.071    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
       "    70495    0.070    0.000    0.070    0.000 utils.py:57(__init__)\n",
       "   140990    0.070    0.000    0.085    0.000 traitlets.py:2526(validate)\n",
       "   423258    0.068    0.000    0.068    0.000 {method 'append' of 'list' objects}\n",
       "    70495    0.059    0.000    0.059    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
       "   141086    0.058    0.000    0.058    0.000 {built-in method __new__ of type object at 0x00007FF9D4705C60}\n",
       "   282172    0.054    0.000    0.054    0.000 {method 'extend' of 'list' objects}\n",
       "   141086    0.053    0.000    0.053    0.000 tz.py:74(utcoffset)\n",
       "   141086    0.050    0.000    0.050    0.000 threading.py:529(is_set)\n",
       "   141086    0.043    0.000    0.043    0.000 {method 'items' of 'dict' objects}\n",
       "   141086    0.036    0.000    0.036    0.000 {method 'append' of 'collections.deque' objects}\n",
       "    70495    0.028    0.000    0.028    0.000 {method 'release' of '_thread.RLock' objects}\n",
       "   141086    0.027    0.000    0.027    0.000 widget.py:792(_trait_to_json)\n",
       "        1    0.002    0.002 18081.568 18081.568 {built-in method builtins.exec}\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:1859(trait_defaults)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:1847(_get_trait_default_generator)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:3359(validate)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:616(default)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2170(make_dynamic_default)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:2145(validate)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:3366(validate_elements)\n",
       "        1    0.000    0.000    0.000    0.000 traitlets.py:1799(has_trait)\n",
       "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%prun\n",
    "def get_root_tree(tree_index, trees):\n",
    "    tree = None\n",
    "    original_index = tree_index\n",
    "    while trees[tree_index] != tree:\n",
    "        tree = trees[tree_index]\n",
    "        tree_index = tree.index\n",
    "    trees[original_index] = tree\n",
    "    return tree\n",
    "\n",
    "try:\n",
    "    while edges_count < fimg.shape[0]-1:\n",
    "        vector_with_min_pair = current_min.argmin()\n",
    "        other_vector = current_min_pairs[vector_with_min_pair] + 1 + vector_with_min_pair\n",
    "        tree1 = get_root_tree(vector_with_min_pair, trees)\n",
    "        tree2 = get_root_tree(other_vector, trees)\n",
    "        if other_vector in tree1 or vector_with_min_pair in tree2:\n",
    "            if not (other_vector in tree1 and vector_with_min_pair in tree2):\n",
    "                print(trees[other_vector], trees[vector_with_min_pair])\n",
    "                raise\n",
    "            \n",
    "            while other_vector in tree1:\n",
    "                kth_argmin = current_min_pairs[vector_with_min_pair]\n",
    "                current_k[vector_with_min_pair] += 1\n",
    "                kth_argmin, kth_min = get_kth_min(cache_path, vector_with_min_pair, current_k[vector_with_min_pair], fimg.shape[0])\n",
    "                current_min[vector_with_min_pair] = kth_min\n",
    "                current_min_pairs[vector_with_min_pair] = kth_argmin\n",
    "                other_vector = current_min_pairs[vector_with_min_pair] + 1 + vector_with_min_pair\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        joined = tree1.join(tree2)\n",
    "#         print(tree2.index, other_vector, end=\">\")\n",
    "        tree2.clear()\n",
    "        tree1.clear()\n",
    "        trees[tree2.index] = joined\n",
    "        trees[tree1.index] = joined\n",
    "        trees[joined.index] = joined\n",
    "        edges_count += 1\n",
    "\n",
    "        kth_argmin = current_min_pairs[vector_with_min_pair]\n",
    "        current_k[vector_with_min_pair] += 1\n",
    "        kth_argmin, kth_min = get_kth_min(cache_path, vector_with_min_pair, current_k[vector_with_min_pair], fimg.shape[0])\n",
    "        current_min[vector_with_min_pair] = kth_min\n",
    "        current_min_pairs[vector_with_min_pair] = kth_argmin\n",
    "        pb.update()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "edges_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1b014b1b970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash import Dash, html\n",
    "import dash_cytoscape as cyto\n",
    "\n",
    "def create_node(i):\n",
    "    return {\"data\": {\"id\": i, \"label\": i}}\n",
    "\n",
    "def create_edge(i,j):\n",
    "    return {\"data\": {\"source\":i, \"target\": j}}\n",
    "\n",
    "cyto.load_extra_layouts()\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.P(\"Dash Cytoscape:\"),\n",
    "    cyto.Cytoscape(\n",
    "        id='cytoscape',\n",
    "        elements=[\n",
    "            *(create_node(i) for i in trees),\n",
    "            *(create_edge(i,tree.index) for i,tree in trees.items() if i != tree.index )\n",
    "        ],\n",
    "        layout={'name': 'dagre',\"rankDir\": 'LR',},\n",
    "        style={'width': '100%', 'height': '1000px', 'border': '3px solid black'}\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = np.zeros(fimg.shape[0]-1)\n",
    "batch_size = 10\n",
    "diff_cache_part = diff_cache[0: triangle_offset(batch_size,fimg.shape[0])]\n",
    "partition_offset = 0\n",
    "for i in tqdm(range(fimg.shape[0]-1)):\n",
    "    start = triangle_offset(i, fimg.shape[0])\n",
    "    end = triangle_offset(i+1, fimg.shape[0])\n",
    "    if (i+1) % batch_size == 0:\n",
    "        diff_cache_part = diff_cache[start: triangle_offset(i+batch_size, fimg.shape[0])]\n",
    "        partition_offset = start\n",
    "    min_value[i] = diff_cache_part[start - partition_offset + current_min_pairs[i]]\n",
    "min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(fimg.shape[0]-1):\n",
    "    start = triangle_offset(i, fimg.shape[0])\n",
    "    end = triangle_offset(i+1, fimg.shape[0])\n",
    "    if end <= start:\n",
    "        print(i,start,end)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.stat(cache_path).st_size/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cache[25087664554:25087665222], diff_cache.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%prun\n",
    "\n",
    "\n",
    "def get_distance(p1,p2,img, dist=np.linalg.norm):\n",
    "    print(img[p2].shape, img[p1].shape )\n",
    "    return dist(img[p2]-img[p1], axis=-1)\n",
    "\n",
    "def get_min_dist_pair(img):\n",
    "    original_shape = img.shape\n",
    "    img = img.reshape(-1,img.shape[-1])\n",
    "    \n",
    "    min_distance = np.inf\n",
    "    min_pair = None\n",
    "    for vector in range(img.shape[0]):\n",
    "        if vector == 1000:\n",
    "            break\n",
    "        dist = get_distance(vector, slice(1+vector,None), img)\n",
    "        arg_min = np.argmin(dist) \n",
    "        \n",
    "        if dist[arg_min] >= min_distance:\n",
    "            continue\n",
    "        min_pair = (np.unravel_index(vector, original_shape[:2]), np.unravel_index(arg_min + vector, original_shape[:2]))\n",
    "        min_distance = dist[arg_min]\n",
    "    return min_pair\n",
    "\n",
    "def find_closest_clusters(trees, img):\n",
    "    m1, m2 = get_min_dist_pair(img)\n",
    "    t1, t2 = None, None\n",
    "    for tree in trees:\n",
    "        if m1 in tree:\n",
    "            t1 = tree\n",
    "        if m2 in tree:\n",
    "            t2 = tree\n",
    "    return t1,t2\n",
    "\n",
    "def single_linkage_heir(img):\n",
    "    trees = {}\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            tree = Leaf((i,j))\n",
    "            trees[tree.index] = tree\n",
    "    memory = np.ones(img.shape[:2])\n",
    "    while len(trees) > 1:\n",
    "        tree1, tree2  = find_closest_clusters(trees.values(), img)\n",
    "        print(tree1.index, tree2.index)\n",
    "        tree_joineed = tree1.join(tree2)\n",
    "        trees.pop(tree1.index)\n",
    "        trees.pop(tree2.index)\n",
    "        break\n",
    "\n",
    "single_linkage_heir(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(16).reshape(4,4)\n",
    "\n",
    "Au = np.triu(A)\n",
    "Au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n-1 + n-2+ ... + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "280*800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "indexing the distance would be practically impossible in RAM\n",
    "~(200*800)^2=50176000000 which is about 46 GB of RAM for single byte precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "dfcdbe84488c61d1d3257810f6248fb9784a7a1f1ab0b54f122168a81a48c4b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
